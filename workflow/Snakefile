configfile: "config/config.yaml"


import itertools, glob

todo = [
    expand(
        "results/{dataset}/statistics/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{grid}.stats.json",
        **config["experiments"][experiment]
    )
    for experiment in config["experiments"]
]
todo = list(itertools.chain(*todo))


rule all:
    input:
        todo,


rule download_mnist:
    output:
        x_raw="results/mnist/features/pixel_raw.npy",
        x_pca="results/mnist/features/pca_raw.npy",
        y_raw="results/mnist/targets/ten-digits_raw.npy",
        y_odd="results/mnist/targets/odd-even_raw.npy",
    script:
        "scripts/download_mnist.py"


rule dummy_covariate_files:
    output:
        none="results/{dataset}/covariates/none.npy",
        balanced="results/{dataset}/covariates/balanced.npy",
    run:
        import numpy as np

        np.save(output.none, [])
        np.save(output.balanced, [])


rule confound_regression:
    input:
        features="results/{dataset}/{targets_or_features}/{name}_raw.npy",
        confounds="results/{dataset}/covariates/{confounds}.npy",
    output:
        features="results/{dataset}/{targets_or_features}/{name}_{confounds}.npy",
    script:
        "scripts/confound_regression.py"


rule split:
    input:
        features="results/{dataset}/features/{features}_{features_trafo}.npy",
        targets="results/{dataset}/targets/{targets}_{targets_trafo}.npy",
        matching="results/{dataset}/covariates/{matching}.npy",
    params:
        val_test_frac=config["val_test_frac"],
        val_test_max=config["val_test_max"],
        stratify=config["stratify"],
    output:
        split="results/{dataset}/splits/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{samplesize}_{seed}.json",
    script:
        "scripts/generate_splits.py"


rule fit:
    input:
        features="results/{dataset}/features/{features}_{features_trafo}.npy",
        targets="results/{dataset}/targets/{targets}_{targets_trafo}.npy",
        split="results/{dataset}/splits/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{samplesize}_{seed}.json",
        grid="config/grids/{grid}.yaml",
    params:
        existing_scores=lambda wildcards: glob.glob(
            "results/{dataset}/fits/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{samplesize}_{seed}_*.csv".format(
                **wildcards
            )
        ),
    output:
        scores="results/{dataset}/fits/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{samplesize}_{seed}_{grid}.csv",
    script:
        "scripts/fit_model.py"


rule aggregate:
    input:
        scores=expand(
            "results/{{dataset}}/fits/{{model}}/{{features}}_{{features_trafo}}_{{targets}}_{{targets_trafo}}_{{matching}}_{samplesize}_{seed}_{{grid}}.csv",
            seed=config["seeds"],
            samplesize=config["sample_sizes"],
        ),
    output:
        scores="results/{dataset}/scores/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{grid}.csv",
    script:
        "scripts/aggregate.py"


rule extrapolate:
    input:
        scores="results/{dataset}/scores/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{grid}.csv",
    params:
        bootstrap_repetitions=config["bootstrap_repetitions"],
    output:
        stats="results/{dataset}/statistics/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{grid}.stats.json",
        bootstraps="results/{dataset}/statistics/{model}/{features}_{features_trafo}_{targets}_{targets_trafo}_{matching}_{grid}.bootstrap.json",
    script:
        "scripts/extrapolate.py"
